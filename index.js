import express from "express";
import http from "http";
import { WebSocketServer } from "ws";
import ffmpeg from "ffmpeg-static";
import { spawn } from "child_process";
import { Blob } from "buffer";
const app = express();
const server = http.createServer(app);

const twiml = `
<Response>
  <Start>
    <Stream url="wss://ai-phone-final.onrender.com/stream" />
  </Start>
  <Pause length="600"/>
</Response>
`;

app.post("/voice", (req, res) => {
  res.type("text/xml").send(twiml);
});
app.get("/voice", (req, res) => {
  res.type("text/xml").send(twiml);
});

// Î¼-law â†’ WAV
function mulawToWav(mulawBuffer) {
  return new Promise((resolve, reject) => {
    const ff = spawn(ffmpeg, [
      "-f", "mulaw",
      "-ar", "8000",
      "-ac", "1",
      "-i", "pipe:0",
      "-f", "wav",
      "pipe:1"
    ]);
    const out = [];
    ff.stdout.on("data", d => out.push(d));
    ff.on("close", () => resolve(Buffer.concat(out)));
    ff.on("error", reject);
    ff.stdin.write(mulawBuffer);
    ff.stdin.end();
  });
}

const wss = new WebSocketServer({ noServer: true });
let chunks = [];

server.on("upgrade", (req, socket, head) => {
  if (req.url === "/stream") {
    wss.handleUpgrade(req, socket, head, ws => {
      wss.emit("connection", ws);
    });
  } else socket.destroy();
});

wss.on("connection", ws => {
  console.log("ðŸ“ž WebSocket æŽ¥ç¶š");

  ws.on("message", async msg => {
    const d = JSON.parse(msg);

    if (d.event === "start") {
      chunks = [];
      console.log("â–¶ï¸ é€šè©±é–‹å§‹");
    }

    if (d.event === "media") {
      const buf = Buffer.from(d.media.payload, "base64");
      chunks.push(buf);
    }

   if (d.event === "stop") {
  console.log("â¹ é€šè©±çµ‚äº†");

  const audio = Buffer.concat(chunks);
const wavAudio = await mulawToWav(audio);

const form = new FormData();
const blob = new Blob([wavAudio], { type: "audio/wav" });

form.append("file", blob, "audio.wav");
form.append("model", "whisper-1");
form.append("language", "ja");
  const r = await fetch("https://api.openai.com/v1/audio/transcriptions", {
    method: "POST",
    headers: {
      Authorization: `Bearer ${process.env.OPENAI_API_KEY}`
    },
    body: form
  });

const j = await r.json();
console.log("ðŸ§ª Whisper raw:", j);
console.log("ðŸ“ Whisper:", j.text);

if (!j.text) return;

// ===== B: ChatGPTã§è¿”ç­”ã‚’ä½œã‚‹ =====
const cr = await fetch("https://api.openai.com/v1/chat/completions", {
  method: "POST",
  headers: {
    Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
    "Content-Type": "application/json"
  },
  body: JSON.stringify({
    model: "gpt-4o-mini",
    messages: [
      {
        role: "system",
        content: "ã‚ãªãŸã¯é£²é£Ÿåº—ã®é›»è©±å—ä»˜AIã§ã™ã€‚ä¸å¯§ãªæ¨™æº–èªžã§å¯¾å¿œã—ã¦ãã ã•ã„ã€‚"
      },
      { role: "user", content: j.text }
    ]
  })
});

const cj = await cr.json();
const replyText = cj.choices[0].message.content;
console.log("ðŸ¤– AIã®è¿”ç­”:", replyText);

// ===== C: TTSï¼ˆå–‹ã‚‰ã›ã‚‹ï¼‰=====
const ttsRes = await fetch("https://api.openai.com/v1/audio/speech", {
  method: "POST",
  headers: {
    Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
    "Content-Type": "application/json"
  },
  body: JSON.stringify({
    model: "gpt-4o-mini-tts",
    voice: "alloy",
    format: "mulaw",   // Twilioå‘ã‘
    input: replyText
  })
});

const audioBuf = Buffer.from(await ttsRes.arrayBuffer());
const audioBase64 = audioBuf.toString("base64");

// ===== é›»è©±ã«éŸ³å£°ã‚’è¿”ã™ =====
ws.send(JSON.stringify({
  event: "media",
  media: {
    payload: audioBase64
  }
}));
      if (j.text) {
        console.log("ðŸ“ Whisper:", j.text);
      } else {
        console.log("âŒ Whisper failed");
      }
    }
  });
});

server.listen(process.env.PORT || 3000, () =>
  console.log("Server running")
);
